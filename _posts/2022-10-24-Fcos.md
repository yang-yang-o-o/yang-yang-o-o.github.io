---
title: "Fcos论文阅读"
layout: post
date: 2022-10-24 22:48
# image: /assets/images/markdown.jpg
# headerImage: false
tag:
- 2d检测
category: blog
# author: jamesfoster
# description: Markdown summary with different options
---

### 1、contribution
    
- 提出了一种逐像素预测的全卷积单阶段目标检测方法，全卷积范式易于与其他任务结合，例如深度估计。
- anchor free
    - 避免了训练过程中与anchor box相关的计算，如计算IOU、分配正负样本等
    - 避免了与anchor box相关的所有超参数，这些超参数对于最终的检测性能非常敏感，例如anchor box的尺寸、宽高比和数量。超参数可能不能很好适应新的domain，即预定义的anchor box也阻碍了检测器的泛化性能。如YOLO算法会使用9种不同大小的anchor box，过多的负样本会加剧训练中的正负样本不平衡
    - postprocess简化，仅需要NMS

### 2、网络结构

#### - 全卷积逐像素

<center>
<img src="https://github.com/yang-yang-o-o/yang-yang-o-o.github.io/blob/main/assets/fcos/fcos_network.png?raw=true" width = "90%" height = "90%"/>
</center>
网络输入HxWxC的图像，经过一个backbone和FPN，输出5个level的feature map，分别为【8、16、32、64、128】倍降采样，5个level的feature map 先后经过同一个Head(共享权重)，最终输出HxWx（4+1+C），即feature map上每个点只产生一个预测，yolo每个点产生的预测数量是由这个点的anchor box的数量决定的。FCOS的网络输出变量是yolo的1/9（每个位置有9个anchor box）。

如果feature map 上的一个位置P(x,y)映射回输入图像为位置p(s/2+xs,s/2+ys)，如果p落在任何一个GT-box内部，那么这个位置P(x,y)被认为是正样本，标签类别就是这个GTbox的类别，否则就是一个负样本，标签类别设为背景类别0。4D实向量t*=(L*，T*，R*，B*)作为位置P(x,y)的回归target，L*，T*，R*，B*是从位置p(s/2+xs,s/2+ys)到GTbox四边的图像距离，如果位置p(s/2+xs,s/2+ys)同时落入多个GT-box，则选择面积最小的作为回归的target

基于该正样本选择策略，FCOS可以利用尽可能多的前景样本来训练回归器。它与anchor-based检测器不同，anchor-based检测方法只考虑具有足够高的IOU的anchor box作为正样本。

<center>
<img src="https://github.com/yang-yang-o-o/yang-yang-o-o.github.io/blob/main/assets/fcos/fcos_loss.png?raw=true" width = "60%" height = "60%"/>
</center>
其中Lcls是focal loss，Lreg是IOU损失。Nops是指正样本的个数，入是Lreg的平衡权重（论文中为1）。求和是在特征图Fi的所有位置上计算的，1{c*>0}是指示函数，如果c*>0，则为1，正样本计算分类和回归损失，负样本只计算分类损失。

#### - 基于FPN的多级预测

多层次预测能提高召回率和解决重叠边界框导致的歧义问题。不同于anchor-based方法将不同大小的anchor box分配到不同的feature level，Fcos直接限制了每个级别的box回归的范围，先计算所有feature level上每个位置P(x,y)的回归指标L*、T*、R*，B*，如果一个位置满足max(L*，t*，r*，b*) > mi 或者 max(L*，t*，r*，b*) < mi-1，则它在feature level i 上被设置为负样本，不需要回归边界框。mi是feature level i 需要回归的最大距离，论文里m2、m3、m4、m5、m6和m7分别设为0、64、128、256、512和正无穷。由于不同大小的对象被分配到不同的特征层，大多数重叠发生在大小相差很大的对象之间。如果一个位置p(s/2+xs,s/2+ys)，即使使用多级预测，仍然分配给多个GT，只需选择最小面积的GT作为target。

在不同的特征层之间共享HEAD（共享权重），为了适应不同的feature level需要回归的不同大小范围，在处理模型输出时，不使用标准的exp(x)，而是使用带有可训练标量si的exp(si*x)来为feature level i自动调整指数函数的基数。

#### - Centerness

远离物体中心的位置会产生许多低质量的预测边界框，Centerness有助于抑制低质量的检测边界框，Centerness表示从位置p(s/2+xs,s/2+ys)到目标中心的归一化距离：
<center>
<img src="https://github.com/yang-yang-o-o/yang-yang-o-o.github.io/blob/main/assets/fcos/fcos_centerness.png?raw=true" width = "60%" height = "60%"/>
</center>

可以额外增加一个超参数，只使用GT-box的中心部分作为正样本，提高检测性能。

### 3、训练和推理

#### - 前向推理结果output张量

5个level的HxW上每个点c都预测1个centerness、C个类别、4个box参数（点c在原图上的投影点到点c所预测的检测框4个边界的距离l、t、r、b），如果只预测C个类别和4个box参数，那么一个物体会被多个点c预测检测框，区分不开检测框的质量高低。此时引入centerness的概念，每个centerness的gt定义为点c在原图上的投影到gt box中心之间的距离，这样预测的centerness越高，表示预测框越接近物体的gt框。最后做NMS的时候，是用centerness乘到C个类别之后的值来做。虽然没有anchor（不同形状和大小的anchor来适应不同形状和大小的物体），但是由于多尺度和centerness的存在，大物体和小物体都能被一个特定level上的点c来很好的预测，通常low level预测小物体，high level预测大物体。

#### - 如何根据标签生成target张量

目的是将feature map上的每个点都分成正负样本，负样本的话，只计算其标签类别，正样本的话，计算标签类别、target box、Centerness。

计算每个feature map上的点在输入图像内的投影点，对于那些投影点不在任何GT-box内的feature点，直接设置为负样本，标签类别设置为0，对于那些投影点落在GT-box内的feature点，根据前面提到的多级预测的阈值设置，将某个feature level上的feature点设置为正样本，其他feature level上的点设置为负样本。正样本的类别设置为GT-box的类别，正样本的target box在输入图像上计算，然后投影到feature map上，然后在feature map上根据target box计算Centerness。

还可以在GT-box内以离box中心的距离设置一个范围，投影点落在范围内才为正样本，范围外为负样本。

#### - 如何根据output张量和target张量来计算loss

- 类别损失
正负样本都计算类别损失，求和后除以正样本个数，使用SigmoidFocalLoss

- box回归损失
正样本计算box回归损失，求和后除以正样本个数，使用Giou loss

- Centerness损失
正样本计算Centerness损失，求和后除以正样本个数，使用BCEWithLogitsLoss

#### - 推理时如何从output张量中解析出最终的检测结果

- 循环处理每个feature level的feature map，对于每个feature map上的feature点，将Centerness乘到类别概率上，然后取出高于阈值的，再对取出的做nms，为最后保留下的feature点构建检测结果输出。
